{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1  \n",
    "# Automatically reload bioscout package\n",
    "%aimport bioscout_tech_challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8adcd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioscout_tech_challenge import *\n",
    "# Now any changes to your package will be automatically reloaded\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88680ff1",
   "metadata": {},
   "source": [
    "## Pre-Process Weather Data\n",
    "\n",
    "Things to look at \n",
    "- extra_information column\n",
    "- storage \n",
    "- autodetect header from mutliple files\n",
    "- extract out of sensors to other tables\n",
    "- add new data to existing tables\n",
    "- write to sql db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e068f5",
   "metadata": {},
   "source": [
    "### Merge Weather and Devices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2de255",
   "metadata": {},
   "source": [
    "Hardcode some data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76efb56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['device_id', 'device_name', 'site_id', 'utc_offset_in_hours',\n",
      "       'longitude', 'latitude'],\n",
      "      dtype='object')\n",
      "Index(['index', 'weather_reading_id', 'date_measured', 'device_id', 'voc',\n",
      "       'pressure', 'extra_information'],\n",
      "      dtype='object')\n",
      "index                                                           7243411\n",
      "weather_reading_id                                              9983574\n",
      "date_measured                                 2024-10-19 11:56:31+00:00\n",
      "device_id                                                           259\n",
      "voc                                                              9400.0\n",
      "pressure                                                        10246.0\n",
      "extra_information     {'VOCs': [{'Value': 9.4, 'Sensor': 'BME680'}],...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "weather_folder = r\"data/tables/weather_data/\"\n",
    "devices_fn = \"weather_devices.csv\"\n",
    "weather_fn = \"weather_data_1.csv\"\n",
    "\n",
    "\n",
    "devices_df = read_csv_file(weather_folder+devices_fn)\n",
    "weather_df = read_csv_file(weather_folder+weather_fn)\n",
    "\n",
    "print(devices_df.columns)\n",
    "print(weather_df.columns)\n",
    "print(weather_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60fb340",
   "metadata": {},
   "source": [
    "Try merging the data check resulting shape makes sense. ie merge_rows = weather_rows and merge columns = weather_columns + device_columns -1 (device_id repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f0eae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 6)\n",
      "(49999, 7)\n",
      "(49999, 12)\n"
     ]
    }
   ],
   "source": [
    "merged_df = merge_weather_data(weather_df,devices_df)\n",
    "#Check shape makes sense\n",
    "print(devices_df.shape)\n",
    "print(weather_df.shape)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a9e8b",
   "metadata": {},
   "source": [
    "Need to check if any rows are missing corresponding device information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53ed6ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [index, device_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if any rows are missing corresponding device information \n",
    "# with function get_na_rows pick a random column from devices_df.\n",
    "print(get_na_rows(merged_df,\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f03561",
   "metadata": {},
   "source": [
    "### Find and join multiple Weather Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3c6a8",
   "metadata": {},
   "source": [
    "Lets try to find multiple files  based on a pattern matching and determine if they all contain header data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec9e5982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/weather_data_1.csv'), PosixPath('/home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/weather_data_2.csv'), PosixPath('/home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/weather_data_3.csv')]\n",
      "infer\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Find all csv files in the weather folder\n",
    "weather_csvs = find_csv_files(weather_folder,prefix=\"weather_data\")\n",
    "print(weather_csvs)\n",
    "\n",
    "# Identify the header for each file\n",
    "for csv in weather_csvs:\n",
    "    print(identify_header(csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8d268",
   "metadata": {},
   "source": [
    "Looks like only the first file has a header. Lets try to combine the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2573a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144399, 8)\n",
      "Index(['index', 'weather_reading_id', 'date_measured', 'device_id', 'voc',\n",
      "       'pressure', 'extra_information', 'source_file'],\n",
      "      dtype='object')\n",
      "index                                                           7243411\n",
      "weather_reading_id                                              9983574\n",
      "date_measured                                 2024-10-19 11:56:31+00:00\n",
      "device_id                                                           259\n",
      "voc                                                              9400.0\n",
      "pressure                                                        10246.0\n",
      "extra_information     {'VOCs': [{'Value': 9.4, 'Sensor': 'BME680'}],...\n",
      "source_file                                          weather_data_1.csv\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "combined_df = combine_csv_files(weather_csvs,detect_header=True)\n",
    "print(combined_df.shape)\n",
    "print(combined_df.columns)\n",
    "print(combined_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f0aee",
   "metadata": {},
   "source": [
    "Now lets try to merge the combined data with the devices data and check if any rows are missing corresponding device information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c2193b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144399, 13)\n",
      "Empty DataFrame\n",
      "Columns: [index, device_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "combined_merged_df = merge_weather_data(combined_df,devices_df)\n",
    "#Check shape makes sense\n",
    "print(combined_merged_df.shape)\n",
    "print(get_na_rows(merged_df,\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f5845",
   "metadata": {},
   "source": [
    "No issues with the data given but is a good check for integration into the end user application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b42b9d",
   "metadata": {},
   "source": [
    "### Parse Extra Information (Flatten extra_information data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922109f",
   "metadata": {},
   "source": [
    "Additional sensor readings are stored in the extra_information column as a json string.\n",
    "We need to parse the json string and flatten the data into a table.\n",
    "Start by looking at the data in a sample row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4032bc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VOCs': [{'Value': 12.044, 'Sensor': 'BME680'}], 'IotID': '0a10aced202194944a051624', 'Humidity': [{'Value': 56.283, 'Sensor': 'BME680'}, {'Value': 100, 'Sensor': 'SHT30'}], 'Pressure': [{'Value': 985.11, 'Sensor': 'BME680'}], 'Rainfall': [{'Value': 0, 'Sensor': 'OpticalRainGauge', 'SampleTimeLength': 300}, {'Value': 0, 'Sensor': 'TippingRainGauge', 'SampleTimeLength': 300}], 'Timestamp': '2024-10-19T15:22:02Z', 'WindSpeed': [{'Value': 0.856, 'Sensor': '40ms_spin_wind'}, {'Value': 1.092, 'Sensor': '60ms_louvre_us'}], 'Temperature': [{'Value': 5.36, 'Sensor': 'BME680'}, {'Value': 4.27291, 'Sensor': 'SHT30'}], 'WindDirection': [{'Value': 298.039, 'Sensor': '40ms_spin_wind'}, {'Value': 112.795, 'Sensor': '60ms_louvre_us'}]}\n"
     ]
    }
   ],
   "source": [
    "index = 500\n",
    "# First get a sample row's extra_information\n",
    "extra_info = combined_merged_df.loc[index]['extra_information']\n",
    "print(extra_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05227a",
   "metadata": {},
   "source": [
    "String dump of a dictionary stored in json format. Lets make this pretty so we can see the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae0f8fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed Extra Information:\n",
      "{   'Humidity': [   {'Sensor': 'BME680', 'Value': 56.283},\n",
      "                    {'Sensor': 'SHT30', 'Value': 100}],\n",
      "    'IotID': '0a10aced202194944a051624',\n",
      "    'Pressure': [{'Sensor': 'BME680', 'Value': 985.11}],\n",
      "    'Rainfall': [   {   'SampleTimeLength': 300,\n",
      "                        'Sensor': 'OpticalRainGauge',\n",
      "                        'Value': 0},\n",
      "                    {   'SampleTimeLength': 300,\n",
      "                        'Sensor': 'TippingRainGauge',\n",
      "                        'Value': 0}],\n",
      "    'Temperature': [   {'Sensor': 'BME680', 'Value': 5.36},\n",
      "                       {'Sensor': 'SHT30', 'Value': 4.27291}],\n",
      "    'Timestamp': '2024-10-19T15:22:02Z',\n",
      "    'VOCs': [{'Sensor': 'BME680', 'Value': 12.044}],\n",
      "    'WindDirection': [   {'Sensor': '40ms_spin_wind', 'Value': 298.039},\n",
      "                         {'Sensor': '60ms_louvre_us', 'Value': 112.795}],\n",
      "    'WindSpeed': [   {'Sensor': '40ms_spin_wind', 'Value': 0.856},\n",
      "                     {'Sensor': '60ms_louvre_us', 'Value': 1.092}]}\n",
      "\n",
      "Rest of Table:\n",
      "date_measured          2024-10-19 15:22:02+00:00\n",
      "device_id                                    262\n",
      "device_name                              WH-0010\n",
      "index                                    7365694\n",
      "latitude                              -43.418845\n",
      "longitude                             171.388011\n",
      "pressure                                  9851.1\n",
      "site_id                                       57\n",
      "source_file                   weather_data_1.csv\n",
      "utc_offset_in_hours                         13.0\n",
      "voc                                      12044.0\n",
      "weather_reading_id                       9987227\n",
      "Name: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the extra_information JSON string to a dictionary\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# The string appears to be double-encoded (both JSON and string literal), so we need to:\n",
    "# 1. Parse the outer JSON\n",
    "# 2. Evaluate the inner string literal as a Python dict\n",
    "def parse_extra_info(json_str):\n",
    "    # First, clean up the string if needed\n",
    "    cleaned_str = json_str.replace(\"'\", '\"')  # Replace single quotes with double quotes\n",
    "    # Parse JSON\n",
    "    return json.loads(cleaned_str)\n",
    "\n",
    "sample_parsed = parse_extra_info(extra_info)\n",
    "# Create a PrettyPrinter instance with desired formatting\n",
    "pp = pprint.PrettyPrinter(indent=4, width=80)\n",
    "print(\"\\nParsed Extra Information:\")\n",
    "pp.pprint(sample_parsed)\n",
    "\n",
    "# lets also compare to the rest of the table\n",
    "columns_to_print = combined_merged_df.columns.difference(['extra_information'])\n",
    "print(\"\\nRest of Table:\")\n",
    "print(combined_merged_df[columns_to_print].loc[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c2582",
   "metadata": {},
   "source": [
    "### Data Inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073534b",
   "metadata": {},
   "source": [
    "Mostly contains sensor readings with a sensor type, device name and reading value. However, there are some other entries that are not sensor readings; Timestamp and IotID. Also pressure and VOC are included again despite aleady having a column in the main table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f64e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Data:\n",
      "Pressure: 985.11\n",
      "VOCs: 12.044\n",
      "\n",
      "Dataframe Data:\n",
      "Pressure: 9851.1\n",
      "VOCs: 12044.0\n"
     ]
    }
   ],
   "source": [
    "# Sanity check of parsed data with existing pressure and VOC readings.\n",
    "print(\"Parsed Data:\")\n",
    "print(f\"Pressure: {sample_parsed['Pressure'][0]['Value']}\")\n",
    "print(f\"VOCs: {sample_parsed['VOCs'][0]['Value']}\")\n",
    "\n",
    "print(\"\\nDataframe Data:\")\n",
    "print(f\"Pressure: {combined_merged_df.loc[index]['pressure']}\")\n",
    "print(f\"VOCs: {combined_merged_df.loc[index]['voc']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41658caf",
   "metadata": {},
   "source": [
    "Tested the above with a few more rows and it seems that pressure is a factor of 10 different and VOCs are a factor of 1000 different. This seems to be consistent based on about 10 checks but we should probably automate this checking when flattening the data.\n",
    "\n",
    "Its unclear how the data was collected and what algorithm was used to calculate the sensor readings. However, the earths pressure is between 900- 1100hPa so the json data seems to be in the correct units.\n",
    "\n",
    "Best solution is probably to add a new column with the units of the sensor reading.\n",
    "\n",
    "Its unclear how the VOC data was transformed. BME680 documentation suggests that it is standard to convert the resistance measured into a IAQ (Indoor Air Quality) reading. However, the key word indoor makes it seem like this might not be the case considering the data is collected outside. \n",
    "\n",
    "Assume the values are converted to the IAQ scale a VOC reading of 500 is considered hazardous and therefore a value of ~10000 is not plausible given the nature of the measurements. However, a reading between 0-50 is excellent air quality which seems likely to be found outdoors on a farm. Therefore, moving forward with the assumption that the json data is in the units of the IAQ scale. (Ideally this would be confirmed with the engineering team)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4334b",
   "metadata": {},
   "source": [
    "#### Flatten Extra Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d7d04",
   "metadata": {},
   "source": [
    "Moving forward we need to flatten each sensor reading into a new row.\n",
    "\n",
    "Therefore we aim to add the following columns to the dataframe:\n",
    "- sensor_type (name of the measurement ie pressure, voc)\n",
    "- sensor_device (name of the device the measurement was taken from)\n",
    "- sensor_reading (value of the measurement)\n",
    "- sensor_units (units of the measurement)\n",
    "\n",
    "whilst dropping the following columns:\n",
    "- extra_information (data has all been flattened)\n",
    "- pressure (will be replaced with sensor_type and sensor_reading)\n",
    "- voc (will be replaced with sensor_type and sensor_reading)\n",
    "\n",
    "Additionally the IotID is new unique information and will be copied over each new expanded row.\n",
    "\n",
    "The timestamp data seems to be consistent with the main dataframe however it would be nice to do a sanity check and flagging any inconsistencies. A simple solution based on the above analysis is to assume the json data is correct and should be the source of truth. Therefore, any timestamp in the main dataframe that disagrees with the timestamp in the json data should be flagged as an inconsistency.\n",
    "\n",
    "\n",
    "Finally a design decision needs to be made about the sensors that have a SampleTimeLength. Whilst the rest of the sensors are assuming to sample a discrete point in time, the rain sensors are collected over a short period.\n",
    "\n",
    "One solution would be to make a sample time length column and fill it with -1 for sensors that do not have a sample time length. This is probably the simplest solution but may not be the best from a data storage perspective. \n",
    "\n",
    "Without knowing the direction of the data in the future this is probably the best solution without introducing my own assumptions unneccesarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b52e11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lets make a sensor schema to help with the parsing\n",
    "# This is a placeholder for now and will be updated as we learn more about the data.\n",
    "# The keys are the sensor types and the values are a list of the sensor type, units.\n",
    "sensor_schema = {\n",
    "    'Humidity': ['humidity', '%'],\n",
    "    'Pressure': ['pressure', 'hPa'],\n",
    "    'Rainfall': ['rainfall', 'mm'],\n",
    "    'Temperature': ['temperature', 'C'],\n",
    "    'VOCs': ['voc', 'IAQ'],\n",
    "    'WindDirection': ['winddirection', 'degrees'],\n",
    "    'WindSpeed': ['windspeed', 'm/s'],\n",
    "}\n",
    "\n",
    "expanded_df = expand_extra_information(combined_merged_df.loc[index],sensor_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ff05630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'weather_reading_id', 'device_id', 'source_file',\n",
      "       'device_name', 'site_id', 'utc_offset_in_hours', 'longitude',\n",
      "       'latitude', 'timezone', 'timestamp', 'iotid', 'sensor_type',\n",
      "       'sensor_device', 'sensor_reading', 'sensor_units',\n",
      "       'sample_time_length'],\n",
      "      dtype='object')\n",
      "       index  weather_reading_id  device_id         source_file device_name  \\\n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "\n",
      "     site_id  utc_offset_in_hours   longitude   latitude          timezone  \\\n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "\n",
      "                timestamp                     iotid    sensor_type  \\\n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624            voc   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       humidity   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       humidity   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       pressure   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       rainfall   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       rainfall   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624      windspeed   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624      windspeed   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624    temperature   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624    temperature   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624  winddirection   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624  winddirection   \n",
      "\n",
      "        sensor_device  sensor_reading sensor_units  sample_time_length  \n",
      "500            BME680        12.04400          IAQ                  -1  \n",
      "500            BME680        56.28300            %                  -1  \n",
      "500             SHT30       100.00000            %                  -1  \n",
      "500            BME680       985.11000          hPa                  -1  \n",
      "500  OpticalRainGauge         0.00000           mm                 300  \n",
      "500  TippingRainGauge         0.00000           mm                 300  \n",
      "500    40ms_spin_wind         0.85600          m/s                  -1  \n",
      "500    60ms_louvre_us         1.09200          m/s                  -1  \n",
      "500            BME680         5.36000            C                  -1  \n",
      "500             SHT30         4.27291            C                  -1  \n",
      "500    40ms_spin_wind       298.03900      degrees                  -1  \n",
      "500    60ms_louvre_us       112.79500      degrees                  -1  \n"
     ]
    }
   ],
   "source": [
    "print(expanded_df.columns)\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178808b",
   "metadata": {},
   "source": [
    "Looks pretty good. Now we need to apply this to the whole dataframe and add the functionality to the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e4f8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'weather_reading_id', 'device_id', 'source_file',\n",
      "       'device_name', 'site_id', 'utc_offset_in_hours', 'longitude',\n",
      "       'latitude', 'timezone', 'timestamp', 'iotid', 'sensor_type',\n",
      "       'sensor_device', 'sensor_reading', 'sensor_units',\n",
      "       'sample_time_length'],\n",
      "      dtype='object')\n",
      "        index  weather_reading_id  device_id         source_file device_name  \\\n",
      "0     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "1     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "2     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "3     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "4     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "...       ...                 ...        ...                 ...         ...   \n",
      "1195  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1196  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1197  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1198  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1199  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "\n",
      "      site_id  utc_offset_in_hours   longitude   latitude          timezone  \\\n",
      "0          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "1          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "2          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "3          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "4          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "...       ...                  ...         ...        ...               ...   \n",
      "1195       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "1196       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "1197       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "1198       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "1199       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "\n",
      "                 timestamp                     iotid    sensor_type  \\\n",
      "0     2024-10-19T11:56:31Z  0a10aced202194944a0514dc            voc   \n",
      "1     2024-10-19T11:56:31Z  0a10aced202194944a0514dc       humidity   \n",
      "2     2024-10-19T11:56:31Z  0a10aced202194944a0514dc       humidity   \n",
      "3     2024-10-19T11:56:31Z  0a10aced202194944a0514dc       pressure   \n",
      "4     2024-10-19T11:56:31Z  0a10aced202194944a0514dc       rainfall   \n",
      "...                    ...                       ...            ...   \n",
      "1195  2024-10-19T21:43:26Z  0a10aced202194944a0515f0      windspeed   \n",
      "1196  2024-10-19T21:43:26Z  0a10aced202194944a0515f0    temperature   \n",
      "1197  2024-10-19T21:43:26Z  0a10aced202194944a0515f0    temperature   \n",
      "1198  2024-10-19T21:43:26Z  0a10aced202194944a0515f0  winddirection   \n",
      "1199  2024-10-19T21:43:26Z  0a10aced202194944a0515f0  winddirection   \n",
      "\n",
      "         sensor_device  sensor_reading sensor_units  sample_time_length  \n",
      "0               BME680          9.4000          IAQ                  -1  \n",
      "1               BME680         54.4820            %                  -1  \n",
      "2                SHT30         90.7881            %                  -1  \n",
      "3               BME680       1024.6000          hPa                  -1  \n",
      "4     OpticalRainGauge          0.0000           mm                 300  \n",
      "...                ...             ...          ...                 ...  \n",
      "1195    60ms_louvre_us          1.3440          m/s                  -1  \n",
      "1196            BME680         22.6800            C                  -1  \n",
      "1197             SHT30         17.5738            C                  -1  \n",
      "1198    40ms_spin_wind        111.9340      degrees                  -1  \n",
      "1199    60ms_louvre_us        321.3740      degrees                  -1  \n",
      "\n",
      "[1200 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    flattened_df\n",
    "except NameError:\n",
    "    flattened_df = expand_weather_dataframe(combined_merged_df[0:100],sensor_schema)\n",
    "print(flattened_df.columns)\n",
    "print(flattened_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6c458",
   "metadata": {},
   "source": [
    "This approach is useful for a small dataframe but is not scalable. We need to find a way to vectorize the process. A quick search suggest that the native python json library is particularly slow and is not suitable for large dataframes.\n",
    "\n",
    "Lets refactor the code and use Pandas json_normalize function. Since this task is not dependent on the device information we can create a function that only deals with the extra_information column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77ae7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_weather_df = flatten_weather_data(combined_merged_df)\n",
    "print(flattened_weather_df.columns)\n",
    "print(flattened_weather_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
