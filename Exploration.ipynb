{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1  \n",
    "# Automatically reload bioscout package\n",
    "%aimport bioscout_tech_challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8adcd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioscout_tech_challenge import *\n",
    "# Now any changes to your package will be automatically reloaded\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88680ff1",
   "metadata": {},
   "source": [
    "## Pre-Process Weather Data\n",
    "\n",
    "Things to look at \n",
    "- extra_information column\n",
    "- storage \n",
    "- autodetect header from mutliple files\n",
    "- extract out of sensors to other tables\n",
    "- add new data to existing tables\n",
    "- write to sql db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e068f5",
   "metadata": {},
   "source": [
    "### Merge Weather and Devices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2de255",
   "metadata": {},
   "source": [
    "Hardcode some data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76efb56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['device_id', 'device_name', 'site_id', 'utc_offset_in_hours',\n",
      "       'longitude', 'latitude'],\n",
      "      dtype='object')\n",
      "Index(['index', 'weather_reading_id', 'date_measured', 'device_id', 'voc',\n",
      "       'pressure', 'extra_information'],\n",
      "      dtype='object')\n",
      "index                                                           7243411\n",
      "weather_reading_id                                              9983574\n",
      "date_measured                                 2024-10-19 11:56:31+00:00\n",
      "device_id                                                           259\n",
      "voc                                                              9400.0\n",
      "pressure                                                        10246.0\n",
      "extra_information     {'VOCs': [{'Value': 9.4, 'Sensor': 'BME680'}],...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "weather_folder = r\"data/tables/weather_data/\"\n",
    "devices_fn = \"weather_devices.csv\"\n",
    "weather_fn = \"weather_data_1.csv\"\n",
    "\n",
    "\n",
    "devices_df = read_csv_file(weather_folder+devices_fn)\n",
    "weather_df = read_csv_file(weather_folder+weather_fn)\n",
    "\n",
    "print(devices_df.columns)\n",
    "print(weather_df.columns)\n",
    "print(weather_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60fb340",
   "metadata": {},
   "source": [
    "Try merging the data check resulting shape makes sense. ie merge_rows = weather_rows and merge columns = weather_columns + device_columns -1 (device_id repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0eae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 6)\n",
      "(49999, 7)\n",
      "(49999, 12)\n"
     ]
    }
   ],
   "source": [
    "merged_df = merge_weather_data(weather_df,devices_df)\n",
    "#Check shape makes sense\n",
    "print(devices_df.shape)\n",
    "print(weather_df.shape)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a9e8b",
   "metadata": {},
   "source": [
    "Need to check if any rows are missing corresponding device information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ed6ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [index, device_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if any rows are missing corresponding device information \n",
    "# with function get_na_rows pick a random column from devices_df.\n",
    "print(get_na_rows(merged_df,\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f03561",
   "metadata": {},
   "source": [
    "### Find and join multiple Weather Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3c6a8",
   "metadata": {},
   "source": [
    "Lets try to find multiple files  based on a pattern matching and determine if they all contain header data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec9e5982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/weather_data_1.csv'), PosixPath('/home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/weather_data_2.csv'), PosixPath('/home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/weather_data_3.csv')]\n",
      "infer\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Find all csv files in the weather folder\n",
    "weather_csvs = find_csv_files(weather_folder,prefix=\"weather_data\")\n",
    "print(weather_csvs)\n",
    "\n",
    "# Identify the header for each file\n",
    "for csv in weather_csvs:\n",
    "    print(identify_header(csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8d268",
   "metadata": {},
   "source": [
    "Looks like only the first file has a header. Lets try to combine the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2573a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144399, 8)\n",
      "Index(['index', 'weather_reading_id', 'date_measured', 'device_id', 'voc',\n",
      "       'pressure', 'extra_information', 'source_file'],\n",
      "      dtype='object')\n",
      "index                                                           7243411\n",
      "weather_reading_id                                              9983574\n",
      "date_measured                                 2024-10-19 11:56:31+00:00\n",
      "device_id                                                           259\n",
      "voc                                                              9400.0\n",
      "pressure                                                        10246.0\n",
      "extra_information     {'VOCs': [{'Value': 9.4, 'Sensor': 'BME680'}],...\n",
      "source_file                                          weather_data_1.csv\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "combined_df = combine_csv_files(weather_csvs,detect_header=True)\n",
    "print(combined_df.shape)\n",
    "print(combined_df.columns)\n",
    "print(combined_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f0aee",
   "metadata": {},
   "source": [
    "Now lets try to merge the combined data with the devices data and check if any rows are missing corresponding device information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c2193b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144399, 13)\n",
      "Empty DataFrame\n",
      "Columns: [index, device_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "combined_merged_df = merge_weather_data(combined_df,devices_df)\n",
    "#Check shape makes sense\n",
    "print(combined_merged_df.shape)\n",
    "print(get_na_rows(merged_df,\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f5845",
   "metadata": {},
   "source": [
    "No issues with the data given but is a good check for integration into the end user application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b42b9d",
   "metadata": {},
   "source": [
    "### Parse Extra Information (Flatten extra_information data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922109f",
   "metadata": {},
   "source": [
    "Additional sensor readings are stored in the extra_information column as a json string.\n",
    "We need to parse the json string and flatten the data into a table.\n",
    "Start by looking at the data in a sample row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4032bc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VOCs': [{'Value': 12.044, 'Sensor': 'BME680'}], 'IotID': '0a10aced202194944a051624', 'Humidity': [{'Value': 56.283, 'Sensor': 'BME680'}, {'Value': 100, 'Sensor': 'SHT30'}], 'Pressure': [{'Value': 985.11, 'Sensor': 'BME680'}], 'Rainfall': [{'Value': 0, 'Sensor': 'OpticalRainGauge', 'SampleTimeLength': 300}, {'Value': 0, 'Sensor': 'TippingRainGauge', 'SampleTimeLength': 300}], 'Timestamp': '2024-10-19T15:22:02Z', 'WindSpeed': [{'Value': 0.856, 'Sensor': '40ms_spin_wind'}, {'Value': 1.092, 'Sensor': '60ms_louvre_us'}], 'Temperature': [{'Value': 5.36, 'Sensor': 'BME680'}, {'Value': 4.27291, 'Sensor': 'SHT30'}], 'WindDirection': [{'Value': 298.039, 'Sensor': '40ms_spin_wind'}, {'Value': 112.795, 'Sensor': '60ms_louvre_us'}]}\n"
     ]
    }
   ],
   "source": [
    "index = 500\n",
    "# First get a sample row's extra_information\n",
    "extra_info = combined_merged_df.loc[index]['extra_information']\n",
    "print(extra_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05227a",
   "metadata": {},
   "source": [
    "String dump of a dictionary stored in json format. Lets make this pretty so we can see the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0f8fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed Extra Information:\n",
      "{   'Humidity': [   {'Sensor': 'BME680', 'Value': 56.283},\n",
      "                    {'Sensor': 'SHT30', 'Value': 100}],\n",
      "    'IotID': '0a10aced202194944a051624',\n",
      "    'Pressure': [{'Sensor': 'BME680', 'Value': 985.11}],\n",
      "    'Rainfall': [   {   'SampleTimeLength': 300,\n",
      "                        'Sensor': 'OpticalRainGauge',\n",
      "                        'Value': 0},\n",
      "                    {   'SampleTimeLength': 300,\n",
      "                        'Sensor': 'TippingRainGauge',\n",
      "                        'Value': 0}],\n",
      "    'Temperature': [   {'Sensor': 'BME680', 'Value': 5.36},\n",
      "                       {'Sensor': 'SHT30', 'Value': 4.27291}],\n",
      "    'Timestamp': '2024-10-19T15:22:02Z',\n",
      "    'VOCs': [{'Sensor': 'BME680', 'Value': 12.044}],\n",
      "    'WindDirection': [   {'Sensor': '40ms_spin_wind', 'Value': 298.039},\n",
      "                         {'Sensor': '60ms_louvre_us', 'Value': 112.795}],\n",
      "    'WindSpeed': [   {'Sensor': '40ms_spin_wind', 'Value': 0.856},\n",
      "                     {'Sensor': '60ms_louvre_us', 'Value': 1.092}]}\n",
      "\n",
      "Rest of Table:\n",
      "date_measured          2024-10-19 15:22:02+00:00\n",
      "device_id                                    262\n",
      "device_name                              WH-0010\n",
      "index                                    7365694\n",
      "latitude                              -43.418845\n",
      "longitude                             171.388011\n",
      "pressure                                  9851.1\n",
      "site_id                                       57\n",
      "source_file                   weather_data_1.csv\n",
      "utc_offset_in_hours                         13.0\n",
      "voc                                      12044.0\n",
      "weather_reading_id                       9987227\n",
      "Name: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the extra_information JSON string to a dictionary\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# The string appears to be double-encoded (both JSON and string literal), so we need to:\n",
    "# 1. Parse the outer JSON\n",
    "# 2. Evaluate the inner string literal as a Python dict\n",
    "def parse_extra_info(json_str):\n",
    "    # First, clean up the string if needed\n",
    "    cleaned_str = json_str.replace(\"'\", '\"')  # Replace single quotes with double quotes\n",
    "    # Parse JSON\n",
    "    return json.loads(cleaned_str)\n",
    "\n",
    "sample_parsed = parse_extra_info(extra_info)\n",
    "# Create a PrettyPrinter instance with desired formatting\n",
    "pp = pprint.PrettyPrinter(indent=4, width=80)\n",
    "print(\"\\nParsed Extra Information:\")\n",
    "pp.pprint(sample_parsed)\n",
    "\n",
    "# lets also compare to the rest of the table\n",
    "columns_to_print = combined_merged_df.columns.difference(['extra_information'])\n",
    "print(\"\\nRest of Table:\")\n",
    "print(combined_merged_df[columns_to_print].loc[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c2582",
   "metadata": {},
   "source": [
    "### Data Inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073534b",
   "metadata": {},
   "source": [
    "Mostly contains sensor readings with a sensor type, device name and reading value. However, there are some other entries that are not sensor readings; Timestamp and IotID. Also pressure and VOC are included again despite aleady having a column in the main table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f64e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Data:\n",
      "Pressure: 985.11\n",
      "VOCs: 12.044\n",
      "\n",
      "Dataframe Data:\n",
      "Pressure: 9851.1\n",
      "VOCs: 12044.0\n"
     ]
    }
   ],
   "source": [
    "# Sanity check of parsed data with existing pressure and VOC readings.\n",
    "print(\"Parsed Data:\")\n",
    "print(f\"Pressure: {sample_parsed['Pressure'][0]['Value']}\")\n",
    "print(f\"VOCs: {sample_parsed['VOCs'][0]['Value']}\")\n",
    "\n",
    "print(\"\\nDataframe Data:\")\n",
    "print(f\"Pressure: {combined_merged_df.loc[index]['pressure']}\")\n",
    "print(f\"VOCs: {combined_merged_df.loc[index]['voc']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41658caf",
   "metadata": {},
   "source": [
    "Tested the above with a few more rows and it seems that pressure is a factor of 10 different and VOCs are a factor of 1000 different. This seems to be consistent based on about 10 checks but we should probably automate this checking when flattening the data.\n",
    "\n",
    "Its unclear how the data was collected and what algorithm was used to calculate the sensor readings. However, the earths pressure is between 900- 1100hPa so the json data seems to be in the correct units.\n",
    "\n",
    "Best solution is probably to add a new column with the units of the sensor reading.\n",
    "\n",
    "Its unclear how the VOC data was transformed. BME680 documentation suggests that it is standard to convert the resistance measured into a IAQ (Indoor Air Quality) reading. However, the key word indoor makes it seem like this might not be the case considering the data is collected outside. \n",
    "\n",
    "Assume the values are converted to the IAQ scale a VOC reading of 500 is considered hazardous and therefore a value of ~10000 is not plausible given the nature of the measurements. However, a reading between 0-50 is excellent air quality which seems likely to be found outdoors on a farm. Therefore, moving forward with the assumption that the json data is in the units of the IAQ scale. (Ideally this would be confirmed with the engineering team)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4334b",
   "metadata": {},
   "source": [
    "#### Flatten Extra Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d7d04",
   "metadata": {},
   "source": [
    "Moving forward we need to flatten each sensor reading into a new row.\n",
    "\n",
    "Therefore we aim to add the following columns to the dataframe:\n",
    "- sensor_type (name of the measurement ie pressure, voc)\n",
    "- sensor_device (name of the device the measurement was taken from)\n",
    "- sensor_reading (value of the measurement)\n",
    "- sensor_units (units of the measurement)\n",
    "\n",
    "whilst dropping the following columns:\n",
    "- extra_information (data has all been flattened)\n",
    "- pressure (will be replaced with sensor_type and sensor_reading)\n",
    "- voc (will be replaced with sensor_type and sensor_reading)\n",
    "\n",
    "Additionally the IotID is new unique information and will be copied over each new expanded row.\n",
    "\n",
    "The timestamp data seems to be consistent with the main dataframe however it would be nice to do a sanity check and flagging any inconsistencies. A simple solution based on the above analysis is to assume the json data is correct and should be the source of truth. Therefore, any timestamp in the main dataframe that disagrees with the timestamp in the json data should be flagged as an inconsistency.\n",
    "\n",
    "\n",
    "Finally a design decision needs to be made about the sensors that have a SampleTimeLength. Whilst the rest of the sensors are assuming to sample a discrete point in time, the rain sensors are collected over a short period.\n",
    "\n",
    "One solution would be to make a sample time length column and fill it with -1 for sensors that do not have a sample time length. This is probably the simplest solution but may not be the best from a data storage perspective. \n",
    "\n",
    "Without knowing the direction of the data in the future this is probably the best solution without introducing my own assumptions unneccesarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b52e11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lets make a sensor schema to help with the parsing\n",
    "# This is a placeholder for now and will be updated as we learn more about the data.\n",
    "# The keys are the sensor types and the values are a list of the sensor type, units.\n",
    "sensor_schema = {\n",
    "    'Humidity': ['humidity', '%'],\n",
    "    'Pressure': ['pressure', 'hPa'],\n",
    "    'Rainfall': ['rainfall', 'mm'],\n",
    "    'Temperature': ['temperature', 'C'],\n",
    "    'VOCs': ['voc', 'IAQ'],\n",
    "    'WindDirection': ['winddirection', 'degrees'],\n",
    "    'WindSpeed': ['windspeed', 'm/s'],\n",
    "}\n",
    "\n",
    "expanded_df = expand_extra_information(combined_merged_df.loc[index],sensor_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff05630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'weather_reading_id', 'device_id', 'source_file',\n",
      "       'device_name', 'site_id', 'utc_offset_in_hours', 'longitude',\n",
      "       'latitude', 'timezone', 'timestamp', 'iotid', 'sensor_type',\n",
      "       'sensor_device', 'sensor_value', 'sensor_units', 'sample_time_length'],\n",
      "      dtype='object')\n",
      "       index  weather_reading_id  device_id         source_file device_name  \\\n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "\n",
      "     site_id  utc_offset_in_hours   longitude   latitude          timezone  \\\n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "500       57                 13.0  171.388011 -43.418845  Pacific/Auckland   \n",
      "\n",
      "                timestamp                     iotid    sensor_type  \\\n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624            voc   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       humidity   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       humidity   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       pressure   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       rainfall   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624       rainfall   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624      windspeed   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624      windspeed   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624    temperature   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624    temperature   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624  winddirection   \n",
      "500  2024-10-19T15:22:02Z  0a10aced202194944a051624  winddirection   \n",
      "\n",
      "        sensor_device  sensor_value sensor_units  sample_time_length  \n",
      "500            BME680      12.04400          IAQ                  -1  \n",
      "500            BME680      56.28300            %                  -1  \n",
      "500             SHT30     100.00000            %                  -1  \n",
      "500            BME680     985.11000          hPa                  -1  \n",
      "500  OpticalRainGauge       0.00000           mm                 300  \n",
      "500  TippingRainGauge       0.00000           mm                 300  \n",
      "500    40ms_spin_wind       0.85600          m/s                  -1  \n",
      "500    60ms_louvre_us       1.09200          m/s                  -1  \n",
      "500            BME680       5.36000            C                  -1  \n",
      "500             SHT30       4.27291            C                  -1  \n",
      "500    40ms_spin_wind     298.03900      degrees                  -1  \n",
      "500    60ms_louvre_us     112.79500      degrees                  -1  \n"
     ]
    }
   ],
   "source": [
    "print(expanded_df.columns)\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178808b",
   "metadata": {},
   "source": [
    "Looks pretty good. Now we need to apply this to the whole dataframe and add the functionality to the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e4f8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'weather_reading_id', 'device_id', 'source_file',\n",
      "       'device_name', 'site_id', 'utc_offset_in_hours', 'longitude',\n",
      "       'latitude', 'timezone', 'timestamp', 'iotid', 'sensor_type',\n",
      "       'sensor_device', 'sensor_value', 'sensor_units', 'sample_time_length'],\n",
      "      dtype='object')\n",
      "        index  weather_reading_id  device_id         source_file device_name  \\\n",
      "0     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "1     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "2     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "3     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "4     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "...       ...                 ...        ...                 ...         ...   \n",
      "1195  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1196  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1197  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1198  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1199  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "\n",
      "      site_id  utc_offset_in_hours   longitude   latitude          timezone  \\\n",
      "0          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "1          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "2          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "3          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "4          63                 13.0  174.129735 -41.272475  Pacific/Auckland   \n",
      "...       ...                  ...         ...        ...               ...   \n",
      "1195       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "1196       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "1197       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "1198       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "1199       83                 13.0  176.456965 -39.885224  Pacific/Auckland   \n",
      "\n",
      "                 timestamp                     iotid    sensor_type  \\\n",
      "0     2024-10-19T11:56:31Z  0a10aced202194944a0514dc            voc   \n",
      "1     2024-10-19T11:56:31Z  0a10aced202194944a0514dc       humidity   \n",
      "2     2024-10-19T11:56:31Z  0a10aced202194944a0514dc       humidity   \n",
      "3     2024-10-19T11:56:31Z  0a10aced202194944a0514dc       pressure   \n",
      "4     2024-10-19T11:56:31Z  0a10aced202194944a0514dc       rainfall   \n",
      "...                    ...                       ...            ...   \n",
      "1195  2024-10-19T21:43:26Z  0a10aced202194944a0515f0      windspeed   \n",
      "1196  2024-10-19T21:43:26Z  0a10aced202194944a0515f0    temperature   \n",
      "1197  2024-10-19T21:43:26Z  0a10aced202194944a0515f0    temperature   \n",
      "1198  2024-10-19T21:43:26Z  0a10aced202194944a0515f0  winddirection   \n",
      "1199  2024-10-19T21:43:26Z  0a10aced202194944a0515f0  winddirection   \n",
      "\n",
      "         sensor_device  sensor_value sensor_units  sample_time_length  \n",
      "0               BME680        9.4000          IAQ                  -1  \n",
      "1               BME680       54.4820            %                  -1  \n",
      "2                SHT30       90.7881            %                  -1  \n",
      "3               BME680     1024.6000          hPa                  -1  \n",
      "4     OpticalRainGauge        0.0000           mm                 300  \n",
      "...                ...           ...          ...                 ...  \n",
      "1195    60ms_louvre_us        1.3440          m/s                  -1  \n",
      "1196            BME680       22.6800            C                  -1  \n",
      "1197             SHT30       17.5738            C                  -1  \n",
      "1198    40ms_spin_wind      111.9340      degrees                  -1  \n",
      "1199    60ms_louvre_us      321.3740      degrees                  -1  \n",
      "\n",
      "[1200 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    flattened_df\n",
    "except NameError:\n",
    "    flattened_df = expand_weather_dataframe(combined_merged_df[0:100],sensor_schema)\n",
    "print(flattened_df.columns)\n",
    "print(flattened_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6c458",
   "metadata": {},
   "source": [
    "This approach is useful for a small dataframe but is not scalable. We need to find a way to vectorize the process. A quick search suggest that the native python json library is particularly slow and is not suitable for large dataframes.\n",
    "\n",
    "Lets refactor the code and use Pandas json_normalize function. Since this task is not dependent on the device information we can create a function that only deals with the extra_information column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77ae7d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Value', 'Sensor', 'IotID', 'Timestamp', 'sensor_type',\n",
      "       'weather_reading_id', 'SampleTimeLength'],\n",
      "      dtype='object')\n",
      "Index(['index', 'weather_reading_id', 'date_measured', 'device_id',\n",
      "       'source_file', 'sensor_value', 'sensor_device', 'iotid', 'timestamp',\n",
      "       'sensor_type', 'sample_time_length'],\n",
      "      dtype='object')\n",
      "            index  weather_reading_id              date_measured  device_id  \\\n",
      "0         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "1         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "2         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "3         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "4         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "...           ...                 ...                        ...        ...   \n",
      "1732783  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "1732784  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "1732785  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "1732786  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "1732787  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "\n",
      "                source_file  sensor_value     sensor_device  \\\n",
      "0        weather_data_1.csv        9.4000            BME680   \n",
      "1        weather_data_1.csv     1024.6000            BME680   \n",
      "2        weather_data_1.csv       54.4820            BME680   \n",
      "3        weather_data_1.csv       90.7881             SHT30   \n",
      "4        weather_data_1.csv        9.0200            BME680   \n",
      "...                     ...           ...               ...   \n",
      "1732783  weather_data_3.csv        2.7360    60ms_louvre_us   \n",
      "1732784  weather_data_3.csv      224.5160    40ms_spin_wind   \n",
      "1732785  weather_data_3.csv       41.7132    60ms_louvre_us   \n",
      "1732786  weather_data_3.csv        0.0000  OpticalRainGauge   \n",
      "1732787  weather_data_3.csv        0.0000  TippingRainGauge   \n",
      "\n",
      "                            iotid             timestamp    sensor_type  \\\n",
      "0        0a10aced202194944a0514dc  2024-10-19T11:56:31Z            voc   \n",
      "1        0a10aced202194944a0514dc  2024-10-19T11:56:31Z       pressure   \n",
      "2        0a10aced202194944a0514dc  2024-10-19T11:56:31Z       humidity   \n",
      "3        0a10aced202194944a0514dc  2024-10-19T11:56:31Z       humidity   \n",
      "4        0a10aced202194944a0514dc  2024-10-19T11:56:31Z    temperature   \n",
      "...                           ...                   ...            ...   \n",
      "1732783  0a10aced202194944a050fdc  2024-10-19T11:53:47Z      windspeed   \n",
      "1732784  0a10aced202194944a050fdc  2024-10-19T11:53:47Z  winddirection   \n",
      "1732785  0a10aced202194944a050fdc  2024-10-19T11:53:47Z  winddirection   \n",
      "1732786  0a10aced202194944a050fdc  2024-10-19T11:53:47Z       rainfall   \n",
      "1732787  0a10aced202194944a050fdc  2024-10-19T11:53:47Z       rainfall   \n",
      "\n",
      "         sample_time_length  \n",
      "0                      -1.0  \n",
      "1                      -1.0  \n",
      "2                      -1.0  \n",
      "3                      -1.0  \n",
      "4                      -1.0  \n",
      "...                     ...  \n",
      "1732783                -1.0  \n",
      "1732784                -1.0  \n",
      "1732785                -1.0  \n",
      "1732786               300.0  \n",
      "1732787               300.0  \n",
      "\n",
      "[1732788 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "flattened_weather_df = flatten_weather_data(combined_df)\n",
    "print(flattened_weather_df.columns)\n",
    "print(flattened_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e33771",
   "metadata": {},
   "source": [
    "Also need to add the sensor units to the dataframe and check the timestamp match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a7cfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "sensor_units = {\n",
    "    'humidity': '%',\n",
    "    'pressure': 'hPa',\n",
    "    'rainfall': 'mm',\n",
    "    'temperature': 'C',\n",
    "    'voc': 'IAQ',\n",
    "    'winddirection': 'degrees',\n",
    "    'windspeed': 'm/s',\n",
    "}\n",
    "\n",
    "flattened_weather_df = add_sensor_units(flattened_weather_df,sensor_units)\n",
    "print(check_timestamp_match(flattened_weather_df))\n",
    "if len(check_timestamp_match(flattened_weather_df)) > 0:\n",
    "    print(\"Warning: Timestamps do not match\")\n",
    "    print(flattened_weather_df.loc[check_timestamp_match(flattened_weather_df)])\n",
    "else:\n",
    "    flattened_weather_df.drop(columns=['date_measured'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21dcde",
   "metadata": {},
   "source": [
    "Need to refactor the changes to the device information table into a separate function for adding a timezone and checking the timestamp. This can be seperate function since it is not dependent on the weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbaa309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['device_id', 'device_name', 'site_id', 'utc_offset_in_hours',\n",
      "       'longitude', 'latitude', 'timezone'],\n",
      "      dtype='object')\n",
      "device_id                           279\n",
      "device_name                     WH-0016\n",
      "site_id                              85\n",
      "utc_offset_in_hours                11.0\n",
      "longitude                    146.730825\n",
      "latitude                     -41.022719\n",
      "timezone               Australia/Hobart\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "devices_timezone_df = add_timezone_from_coordinates(devices_df)\n",
    "print(devices_timezone_df.columns)\n",
    "print(devices_timezone_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15c868",
   "metadata": {},
   "source": [
    "Alright now lets merge the weather and devices dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73c3cf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                                   7365694\n",
      "weather_reading_id                      9987227\n",
      "device_id                                   262\n",
      "source_file                  weather_data_1.csv\n",
      "device_name                             WH-0010\n",
      "site_id                                      57\n",
      "utc_offset_in_hours                        13.0\n",
      "longitude                            171.388011\n",
      "latitude                             -43.418845\n",
      "timezone                       Pacific/Auckland\n",
      "timestamp                  2024-10-19T15:22:02Z\n",
      "iotid                  0a10aced202194944a051624\n",
      "sensor_type                                 voc\n",
      "sensor_device                            BME680\n",
      "sensor_value                             12.044\n",
      "sensor_units                                IAQ\n",
      "sample_time_length                           -1\n",
      "Name: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(expanded_df.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e87faf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'weather_reading_id', 'device_id', 'source_file',\n",
      "       'sensor_value', 'sensor_device', 'iotid', 'timestamp', 'sensor_type',\n",
      "       'sample_time_length', 'sensor_units', 'device_name', 'site_id',\n",
      "       'utc_offset_in_hours', 'longitude', 'latitude', 'timezone'],\n",
      "      dtype='object')\n",
      "index                                   7243411\n",
      "weather_reading_id                      9983574\n",
      "device_id                                   259\n",
      "source_file                  weather_data_1.csv\n",
      "sensor_value                                9.4\n",
      "sensor_device                            BME680\n",
      "iotid                  0a10aced202194944a0514dc\n",
      "timestamp                  2024-10-19T11:56:31Z\n",
      "sensor_type                                 voc\n",
      "sample_time_length                         -1.0\n",
      "sensor_units                                IAQ\n",
      "device_name                             WH-0011\n",
      "site_id                                      63\n",
      "utc_offset_in_hours                        13.0\n",
      "longitude                            174.129735\n",
      "latitude                             -41.272475\n",
      "timezone                       Pacific/Auckland\n",
      "Name: 0, dtype: object\n",
      "index                                   7243411\n",
      "weather_reading_id                      9983574\n",
      "device_id                                   259\n",
      "source_file                  weather_data_1.csv\n",
      "device_name                             WH-0011\n",
      "site_id                                      63\n",
      "utc_offset_in_hours                        13.0\n",
      "longitude                            174.129735\n",
      "latitude                             -41.272475\n",
      "timezone                       Pacific/Auckland\n",
      "timestamp                  2024-10-19T11:56:31Z\n",
      "iotid                  0a10aced202194944a0514dc\n",
      "sensor_type                                 voc\n",
      "sensor_device                            BME680\n",
      "sensor_value                                9.4\n",
      "sensor_units                                IAQ\n",
      "sample_time_length                           -1\n",
      "Name: 0, dtype: object\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "\n",
      "Common columns: {'device_id', 'iotid', 'weather_reading_id', 'device_name', 'utc_offset_in_hours', 'sensor_units', 'timestamp', 'sample_time_length', 'site_id', 'index', 'source_file', 'longitude', 'timezone', 'sensor_value', 'latitude', 'sensor_device', 'sensor_type'}\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "final_df = merge_weather_data(flattened_weather_df,devices_timezone_df)\n",
    "print(final_df.columns)\n",
    "final_row = final_df.loc[0]\n",
    "print(final_row)\n",
    "#compare to original combined_merged_df\n",
    "flattened_row  = flattened_df.loc[0]  \n",
    "print(flattened_row)\n",
    "# find the difference in columns\n",
    "print(final_df.columns.difference(flattened_df.columns))\n",
    "print(flattened_df.columns.difference(final_df.columns))\n",
    "# Find columns that are in both dataframes but have different names\n",
    "common_values = set(final_df.columns) & set(flattened_df.columns)\n",
    "print(\"\\nCommon columns:\", common_values)\n",
    "print(\"Match:\", (final_row[list(common_values)] == flattened_row[list(common_values)]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4d438",
   "metadata": {},
   "source": [
    "Great that works and is much faster. Need to now add the functionality to the package for the end user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "671fd3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sensor_types': ['VOCs', 'Pressure', 'Humidity', 'Temperature', 'WindSpeed', 'WindDirection', 'Rainfall'], 'sensor_mappings': {'Humidity': {'column_name': 'humidity', 'unit': '%'}, 'Pressure': {'column_name': 'pressure', 'unit': 'hPa'}, 'Rainfall': {'column_name': 'rainfall', 'unit': 'mm'}, 'Temperature': {'column_name': 'temperature', 'unit': 'C'}, 'VOCs': {'column_name': 'voc', 'unit': 'IAQ'}, 'WindDirection': {'column_name': 'winddirection', 'unit': 'degrees'}, 'WindSpeed': {'column_name': 'windspeed', 'unit': 'm/s'}}, 'meta_columns': ['IotID', 'Timestamp'], 'column_mapping': {'Value': 'sensor_value', 'Sensor': 'sensor_device', 'IotID': 'iotid', 'SampleTimeLength': 'sample_time_length', 'Timestamp': 'timestamp'}, 'columns_to_drop': ['extra_information', 'pressure', 'voc']}\n"
     ]
    }
   ],
   "source": [
    "# Lets try and load the sensor schema from a json file.\n",
    "sensor_schema = read_json_file(r\"src/bioscout_tech_challenge/data/sensor_schema.json\")\n",
    "print(parse_sensor_schema(sensor_schema))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
