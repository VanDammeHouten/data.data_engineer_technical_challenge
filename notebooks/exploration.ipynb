{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1  \n",
    "# Automatically reload bioscout package\n",
    "%aimport bioscout_tech_challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8adcd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioscout_tech_challenge import *\n",
    "from bioscout_tech_challenge.utils.weather import *\n",
    "from bioscout_tech_challenge.utils.file_operations import *\n",
    "# Now any changes to your package will be automatically reloaded\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88680ff1",
   "metadata": {},
   "source": [
    "## Pre-Process Weather Data\n",
    "\n",
    "Things to look at \n",
    "- extra_information column\n",
    "- storage \n",
    "- autodetect header from mutliple files\n",
    "- extract out of sensors to other tables\n",
    "- add new data to existing tables\n",
    "- write to sql db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e068f5",
   "metadata": {},
   "source": [
    "### Merge Weather and Devices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2de255",
   "metadata": {},
   "source": [
    "Hardcode some data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76efb56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['device_id', 'device_name', 'site_id', 'utc_offset_in_hours',\n",
      "       'longitude', 'latitude'],\n",
      "      dtype='object')\n",
      "Index(['index', 'weather_reading_id', 'date_measured', 'device_id', 'voc',\n",
      "       'pressure', 'extra_information'],\n",
      "      dtype='object')\n",
      "index                                                           7243411\n",
      "weather_reading_id                                              9983574\n",
      "date_measured                                 2024-10-19 11:56:31+00:00\n",
      "device_id                                                           259\n",
      "voc                                                              9400.0\n",
      "pressure                                                        10246.0\n",
      "extra_information     {'VOCs': [{'Value': 9.4, 'Sensor': 'BME680'}],...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "weather_folder = r\"../data/tables/weather_data/\"\n",
    "devices_fn = \"weather_devices.csv\"\n",
    "weather_fn = \"weather_data_1.csv\"\n",
    "\n",
    "\n",
    "devices_df = read_csv_file(weather_folder+devices_fn)\n",
    "weather_df = read_csv_file(weather_folder+weather_fn)\n",
    "\n",
    "print(devices_df.columns)\n",
    "print(weather_df.columns)\n",
    "print(weather_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60fb340",
   "metadata": {},
   "source": [
    "Try merging the data check resulting shape makes sense. ie merge_rows = weather_rows and merge columns = weather_columns + device_columns -1 (device_id repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0eae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 6)\n",
      "(49999, 7)\n",
      "(49999, 12)\n"
     ]
    }
   ],
   "source": [
    "merged_df = merge_weather_data(weather_df,devices_df)\n",
    "#Check shape makes sense\n",
    "print(devices_df.shape)\n",
    "print(weather_df.shape)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a9e8b",
   "metadata": {},
   "source": [
    "Need to check if any rows are missing corresponding device information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ed6ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [index, device_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if any rows are missing corresponding device information \n",
    "# with function get_na_rows pick a random column from devices_df.\n",
    "print(get_na_rows(merged_df,\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f03561",
   "metadata": {},
   "source": [
    "### Find and join multiple Weather Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3c6a8",
   "metadata": {},
   "source": [
    "Lets try to find multiple files  based on a pattern matching and determine if they all contain header data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9e5982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/weather_data_1.csv'), PosixPath('/home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/weather_data_2.csv'), PosixPath('/home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/weather_data_3.csv')]\n",
      "infer\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Find all csv files in the weather folder\n",
    "weather_csvs = find_csv_files(weather_folder,prefix=\"weather_data\")\n",
    "print(weather_csvs)\n",
    "\n",
    "# Identify the header for each file\n",
    "for csv in weather_csvs:\n",
    "    print(identify_header(csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8d268",
   "metadata": {},
   "source": [
    "Looks like only the first file has a header. Lets try to combine the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2573a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144399, 8)\n",
      "Index(['index', 'weather_reading_id', 'date_measured', 'device_id', 'voc',\n",
      "       'pressure', 'extra_information', 'source_file'],\n",
      "      dtype='object')\n",
      "index                                                           7243411\n",
      "weather_reading_id                                              9983574\n",
      "date_measured                                 2024-10-19 11:56:31+00:00\n",
      "device_id                                                           259\n",
      "voc                                                              9400.0\n",
      "pressure                                                        10246.0\n",
      "extra_information     {'VOCs': [{'Value': 9.4, 'Sensor': 'BME680'}],...\n",
      "source_file                                          weather_data_1.csv\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "combined_df = combine_csv_files(weather_csvs,detect_header=True)\n",
    "print(combined_df.shape)\n",
    "print(combined_df.columns)\n",
    "print(combined_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f0aee",
   "metadata": {},
   "source": [
    "Now lets try to merge the combined data with the devices data and check if any rows are missing corresponding device information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c2193b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144399, 13)\n",
      "Empty DataFrame\n",
      "Columns: [index, device_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "combined_merged_df = merge_weather_data(combined_df,devices_df)\n",
    "#Check shape makes sense\n",
    "print(combined_merged_df.shape)\n",
    "print(get_na_rows(merged_df,\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f5845",
   "metadata": {},
   "source": [
    "No issues with the data given but is a good check for integration into the end user application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b42b9d",
   "metadata": {},
   "source": [
    "### Parse Extra Information (Flatten extra_information data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922109f",
   "metadata": {},
   "source": [
    "Additional sensor readings are stored in the extra_information column as a json string.\n",
    "We need to parse the json string and flatten the data into a table.\n",
    "Start by looking at the data in a sample row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4032bc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VOCs': [{'Value': 12.044, 'Sensor': 'BME680'}], 'IotID': '0a10aced202194944a051624', 'Humidity': [{'Value': 56.283, 'Sensor': 'BME680'}, {'Value': 100, 'Sensor': 'SHT30'}], 'Pressure': [{'Value': 985.11, 'Sensor': 'BME680'}], 'Rainfall': [{'Value': 0, 'Sensor': 'OpticalRainGauge', 'SampleTimeLength': 300}, {'Value': 0, 'Sensor': 'TippingRainGauge', 'SampleTimeLength': 300}], 'Timestamp': '2024-10-19T15:22:02Z', 'WindSpeed': [{'Value': 0.856, 'Sensor': '40ms_spin_wind'}, {'Value': 1.092, 'Sensor': '60ms_louvre_us'}], 'Temperature': [{'Value': 5.36, 'Sensor': 'BME680'}, {'Value': 4.27291, 'Sensor': 'SHT30'}], 'WindDirection': [{'Value': 298.039, 'Sensor': '40ms_spin_wind'}, {'Value': 112.795, 'Sensor': '60ms_louvre_us'}]}\n"
     ]
    }
   ],
   "source": [
    "index = 500\n",
    "# First get a sample row's extra_information\n",
    "extra_info = combined_merged_df.loc[index]['extra_information']\n",
    "print(extra_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05227a",
   "metadata": {},
   "source": [
    "String dump of a dictionary stored in json format. Lets make this pretty so we can see the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae0f8fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed Extra Information:\n",
      "{   'Humidity': [   {'Sensor': 'BME680', 'Value': 56.283},\n",
      "                    {'Sensor': 'SHT30', 'Value': 100}],\n",
      "    'IotID': '0a10aced202194944a051624',\n",
      "    'Pressure': [{'Sensor': 'BME680', 'Value': 985.11}],\n",
      "    'Rainfall': [   {   'SampleTimeLength': 300,\n",
      "                        'Sensor': 'OpticalRainGauge',\n",
      "                        'Value': 0},\n",
      "                    {   'SampleTimeLength': 300,\n",
      "                        'Sensor': 'TippingRainGauge',\n",
      "                        'Value': 0}],\n",
      "    'Temperature': [   {'Sensor': 'BME680', 'Value': 5.36},\n",
      "                       {'Sensor': 'SHT30', 'Value': 4.27291}],\n",
      "    'Timestamp': '2024-10-19T15:22:02Z',\n",
      "    'VOCs': [{'Sensor': 'BME680', 'Value': 12.044}],\n",
      "    'WindDirection': [   {'Sensor': '40ms_spin_wind', 'Value': 298.039},\n",
      "                         {'Sensor': '60ms_louvre_us', 'Value': 112.795}],\n",
      "    'WindSpeed': [   {'Sensor': '40ms_spin_wind', 'Value': 0.856},\n",
      "                     {'Sensor': '60ms_louvre_us', 'Value': 1.092}]}\n",
      "\n",
      "Rest of Table:\n",
      "date_measured          2024-10-19 15:22:02+00:00\n",
      "device_id                                    262\n",
      "device_name                              WH-0010\n",
      "index                                    7365694\n",
      "latitude                              -43.418845\n",
      "longitude                             171.388011\n",
      "pressure                                  9851.1\n",
      "site_id                                       57\n",
      "source_file                   weather_data_1.csv\n",
      "utc_offset_in_hours                         13.0\n",
      "voc                                      12044.0\n",
      "weather_reading_id                       9987227\n",
      "Name: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the extra_information JSON string to a dictionary\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# The string appears to be double-encoded (both JSON and string literal), so we need to:\n",
    "# 1. Parse the outer JSON\n",
    "# 2. Evaluate the inner string literal as a Python dict\n",
    "def parse_extra_info(json_str):\n",
    "    # First, clean up the string if needed\n",
    "    cleaned_str = json_str.replace(\"'\", '\"')  # Replace single quotes with double quotes\n",
    "    # Parse JSON\n",
    "    return json.loads(cleaned_str)\n",
    "\n",
    "sample_parsed = parse_extra_info(extra_info)\n",
    "# Create a PrettyPrinter instance with desired formatting\n",
    "pp = pprint.PrettyPrinter(indent=4, width=80)\n",
    "print(\"\\nParsed Extra Information:\")\n",
    "pp.pprint(sample_parsed)\n",
    "\n",
    "# lets also compare to the rest of the table\n",
    "columns_to_print = combined_merged_df.columns.difference(['extra_information'])\n",
    "print(\"\\nRest of Table:\")\n",
    "print(combined_merged_df[columns_to_print].loc[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c2582",
   "metadata": {},
   "source": [
    "### Data Inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073534b",
   "metadata": {},
   "source": [
    "Mostly contains sensor readings with a sensor type, device name and reading value. However, there are some other entries that are not sensor readings; Timestamp and IotID. Also pressure and VOC are included again despite aleady having a column in the main table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f64e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Data:\n",
      "Pressure: 985.11\n",
      "VOCs: 12.044\n",
      "\n",
      "Dataframe Data:\n",
      "Pressure: 9851.1\n",
      "VOCs: 12044.0\n"
     ]
    }
   ],
   "source": [
    "# Sanity check of parsed data with existing pressure and VOC readings.\n",
    "print(\"Parsed Data:\")\n",
    "print(f\"Pressure: {sample_parsed['Pressure'][0]['Value']}\")\n",
    "print(f\"VOCs: {sample_parsed['VOCs'][0]['Value']}\")\n",
    "\n",
    "print(\"\\nDataframe Data:\")\n",
    "print(f\"Pressure: {combined_merged_df.loc[index]['pressure']}\")\n",
    "print(f\"VOCs: {combined_merged_df.loc[index]['voc']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41658caf",
   "metadata": {},
   "source": [
    "Tested the above with a few more rows and it seems that pressure is a factor of 10 different and VOCs are a factor of 1000 different. This seems to be consistent based on about 10 checks but we should probably automate this checking when flattening the data.\n",
    "\n",
    "Its unclear how the data was collected and what algorithm was used to calculate the sensor readings. However, the earths pressure is between 900- 1100hPa so the json data seems to be in the correct units.\n",
    "\n",
    "Best solution is probably to add a new column with the units of the sensor reading.\n",
    "\n",
    "Its unclear how the VOC data was transformed. BME680 documentation suggests that it is standard to convert the resistance measured into a IAQ (Indoor Air Quality) reading. However, the key word indoor makes it seem like this might not be the case considering the data is collected outside. \n",
    "\n",
    "Assume the values are converted to the IAQ scale a VOC reading of 500 is considered hazardous and therefore a value of ~10000 is not plausible given the nature of the measurements. However, a reading between 0-50 is excellent air quality which seems likely to be found outdoors on a farm. Therefore, moving forward with the assumption that the json data is in the units of the IAQ scale. (Ideally this would be confirmed with the engineering team)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4334b",
   "metadata": {},
   "source": [
    "#### Flatten Extra Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d7d04",
   "metadata": {},
   "source": [
    "Moving forward we need to flatten each sensor reading into a new row.\n",
    "\n",
    "Therefore we aim to add the following columns to the dataframe:\n",
    "- sensor_type (name of the measurement ie pressure, voc)\n",
    "- sensor_device (name of the device the measurement was taken from)\n",
    "- sensor_reading (value of the measurement)\n",
    "- sensor_units (units of the measurement)\n",
    "\n",
    "whilst dropping the following columns:\n",
    "- extra_information (data has all been flattened)\n",
    "- pressure (will be replaced with sensor_type and sensor_reading)\n",
    "- voc (will be replaced with sensor_type and sensor_reading)\n",
    "\n",
    "Additionally the IotID is new unique information and will be copied over each new expanded row.\n",
    "\n",
    "The timestamp data seems to be consistent with the main dataframe however it would be nice to do a sanity check and flagging any inconsistencies. A simple solution based on the above analysis is to assume the json data is correct and should be the source of truth. Therefore, any timestamp in the main dataframe that disagrees with the timestamp in the json data should be flagged as an inconsistency.\n",
    "\n",
    "\n",
    "Finally a design decision needs to be made about the sensors that have a SampleTimeLength. Whilst the rest of the sensors are assuming to sample a discrete point in time, the rain sensors are collected over a short period.\n",
    "\n",
    "One solution would be to make a sample time length column and fill it with -1 for sensors that do not have a sample time length. This is probably the simplest solution but may not be the best from a data storage perspective. \n",
    "\n",
    "Without knowing the direction of the data in the future this is probably the best solution without introducing my own assumptions unneccesarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b52e11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lets make a sensor schema to help with the parsing\n",
    "# This is a placeholder for now and will be updated as we learn more about the data.\n",
    "# The keys are the sensor types and the values are a list of the sensor type, units.\n",
    "sensor_schema = {\n",
    "    'Humidity': ['humidity', '%'],\n",
    "    'Pressure': ['pressure', 'hPa'],\n",
    "    'Rainfall': ['rainfall', 'mm'],\n",
    "    'Temperature': ['temperature', 'C'],\n",
    "    'VOCs': ['voc', 'IAQ'],\n",
    "    'WindDirection': ['winddirection', 'degrees'],\n",
    "    'WindSpeed': ['windspeed', 'm/s'],\n",
    "}\n",
    "\n",
    "expanded_df = expand_extra_information(combined_merged_df.loc[index],sensor_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ff05630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'weather_reading_id', 'device_id', 'source_file',\n",
      "       'device_name', 'site_id', 'utc_offset_in_hours', 'longitude',\n",
      "       'latitude', 'timestamp', 'timezone', 'iotid', 'sensor_type',\n",
      "       'sensor_device', 'sensor_value', 'sensor_units', 'sample_time_length'],\n",
      "      dtype='object')\n",
      "       index  weather_reading_id  device_id         source_file device_name  \\\n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "500  7365694             9987227        262  weather_data_1.csv     WH-0010   \n",
      "\n",
      "     site_id  utc_offset_in_hours   longitude   latitude  \\\n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "500       57                 13.0  171.388011 -43.418845   \n",
      "\n",
      "                timestamp          timezone                     iotid  \\\n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "500  2024-10-19T15:22:02Z  Pacific/Auckland  0a10aced202194944a051624   \n",
      "\n",
      "       sensor_type     sensor_device  sensor_value sensor_units  \\\n",
      "500            voc            BME680      12.04400          IAQ   \n",
      "500       humidity            BME680      56.28300            %   \n",
      "500       humidity             SHT30     100.00000            %   \n",
      "500       pressure            BME680     985.11000          hPa   \n",
      "500       rainfall  OpticalRainGauge       0.00000           mm   \n",
      "500       rainfall  TippingRainGauge       0.00000           mm   \n",
      "500      windspeed    40ms_spin_wind       0.85600          m/s   \n",
      "500      windspeed    60ms_louvre_us       1.09200          m/s   \n",
      "500    temperature            BME680       5.36000            C   \n",
      "500    temperature             SHT30       4.27291            C   \n",
      "500  winddirection    40ms_spin_wind     298.03900      degrees   \n",
      "500  winddirection    60ms_louvre_us     112.79500      degrees   \n",
      "\n",
      "     sample_time_length  \n",
      "500                  -1  \n",
      "500                  -1  \n",
      "500                  -1  \n",
      "500                  -1  \n",
      "500                 300  \n",
      "500                 300  \n",
      "500                  -1  \n",
      "500                  -1  \n",
      "500                  -1  \n",
      "500                  -1  \n",
      "500                  -1  \n",
      "500                  -1  \n"
     ]
    }
   ],
   "source": [
    "print(expanded_df.columns)\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178808b",
   "metadata": {},
   "source": [
    "Looks pretty good. Now we need to apply this to the whole dataframe and add the functionality to the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e4f8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'weather_reading_id', 'device_id', 'source_file',\n",
      "       'device_name', 'site_id', 'utc_offset_in_hours', 'longitude',\n",
      "       'latitude', 'timestamp', 'timezone', 'iotid', 'sensor_type',\n",
      "       'sensor_device', 'sensor_value', 'sensor_units', 'sample_time_length'],\n",
      "      dtype='object')\n",
      "        index  weather_reading_id  device_id         source_file device_name  \\\n",
      "0     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "1     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "2     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "3     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "4     7243411             9983574        259  weather_data_1.csv     WH-0011   \n",
      "...       ...                 ...        ...                 ...         ...   \n",
      "1195  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1196  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1197  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1198  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "1199  7263615             9994016        267  weather_data_1.csv     WH-0014   \n",
      "\n",
      "      site_id  utc_offset_in_hours   longitude   latitude  \\\n",
      "0          63                 13.0  174.129735 -41.272475   \n",
      "1          63                 13.0  174.129735 -41.272475   \n",
      "2          63                 13.0  174.129735 -41.272475   \n",
      "3          63                 13.0  174.129735 -41.272475   \n",
      "4          63                 13.0  174.129735 -41.272475   \n",
      "...       ...                  ...         ...        ...   \n",
      "1195       83                 13.0  176.456965 -39.885224   \n",
      "1196       83                 13.0  176.456965 -39.885224   \n",
      "1197       83                 13.0  176.456965 -39.885224   \n",
      "1198       83                 13.0  176.456965 -39.885224   \n",
      "1199       83                 13.0  176.456965 -39.885224   \n",
      "\n",
      "                 timestamp          timezone                     iotid  \\\n",
      "0     2024-10-19T11:56:31Z  Pacific/Auckland  0a10aced202194944a0514dc   \n",
      "1     2024-10-19T11:56:31Z  Pacific/Auckland  0a10aced202194944a0514dc   \n",
      "2     2024-10-19T11:56:31Z  Pacific/Auckland  0a10aced202194944a0514dc   \n",
      "3     2024-10-19T11:56:31Z  Pacific/Auckland  0a10aced202194944a0514dc   \n",
      "4     2024-10-19T11:56:31Z  Pacific/Auckland  0a10aced202194944a0514dc   \n",
      "...                    ...               ...                       ...   \n",
      "1195  2024-10-19T21:43:26Z  Pacific/Auckland  0a10aced202194944a0515f0   \n",
      "1196  2024-10-19T21:43:26Z  Pacific/Auckland  0a10aced202194944a0515f0   \n",
      "1197  2024-10-19T21:43:26Z  Pacific/Auckland  0a10aced202194944a0515f0   \n",
      "1198  2024-10-19T21:43:26Z  Pacific/Auckland  0a10aced202194944a0515f0   \n",
      "1199  2024-10-19T21:43:26Z  Pacific/Auckland  0a10aced202194944a0515f0   \n",
      "\n",
      "        sensor_type     sensor_device  sensor_value sensor_units  \\\n",
      "0               voc            BME680        9.4000          IAQ   \n",
      "1          humidity            BME680       54.4820            %   \n",
      "2          humidity             SHT30       90.7881            %   \n",
      "3          pressure            BME680     1024.6000          hPa   \n",
      "4          rainfall  OpticalRainGauge        0.0000           mm   \n",
      "...             ...               ...           ...          ...   \n",
      "1195      windspeed    60ms_louvre_us        1.3440          m/s   \n",
      "1196    temperature            BME680       22.6800            C   \n",
      "1197    temperature             SHT30       17.5738            C   \n",
      "1198  winddirection    40ms_spin_wind      111.9340      degrees   \n",
      "1199  winddirection    60ms_louvre_us      321.3740      degrees   \n",
      "\n",
      "      sample_time_length  \n",
      "0                     -1  \n",
      "1                     -1  \n",
      "2                     -1  \n",
      "3                     -1  \n",
      "4                    300  \n",
      "...                  ...  \n",
      "1195                  -1  \n",
      "1196                  -1  \n",
      "1197                  -1  \n",
      "1198                  -1  \n",
      "1199                  -1  \n",
      "\n",
      "[1200 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    flattened_df\n",
    "except NameError:\n",
    "    flattened_df = expand_weather_dataframe(combined_merged_df[0:100],sensor_schema)\n",
    "print(flattened_df.columns)\n",
    "print(flattened_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6c458",
   "metadata": {},
   "source": [
    "This approach is useful for a small dataframe but is not scalable. We need to find a way to vectorize the process. A quick search suggest that the native python json library is particularly slow and is not suitable for large dataframes.\n",
    "\n",
    "Lets refactor the code and use Pandas json_normalize function. Since this task is not dependent on the device information we can create a function that only deals with only the extra_information column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77ae7d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'weather_reading_id', 'date_measured', 'device_id',\n",
      "       'source_file', 'sensor_value', 'sensor_device', 'iotid', 'timestamp',\n",
      "       'sensor_type', 'sample_time_length'],\n",
      "      dtype='object')\n",
      "            index  weather_reading_id              date_measured  device_id  \\\n",
      "0         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "1         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "2         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "3         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "4         7243411             9983574  2024-10-19 11:56:31+00:00        259   \n",
      "...           ...                 ...                        ...        ...   \n",
      "1732783  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "1732784  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "1732785  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "1732786  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "1732787  10342010             9983536  2024-10-19 11:53:47+00:00        258   \n",
      "\n",
      "                source_file  sensor_value        sensor_device  \\\n",
      "0        weather_data_1.csv        9.4000            b'BME680'   \n",
      "1        weather_data_1.csv     1024.6000            b'BME680'   \n",
      "2        weather_data_1.csv       54.4820            b'BME680'   \n",
      "3        weather_data_1.csv       90.7881             b'SHT30'   \n",
      "4        weather_data_1.csv        9.0200            b'BME680'   \n",
      "...                     ...           ...                  ...   \n",
      "1732783  weather_data_3.csv        2.7360    b'60ms_louvre_us'   \n",
      "1732784  weather_data_3.csv      224.5160    b'40ms_spin_wind'   \n",
      "1732785  weather_data_3.csv       41.7132    b'60ms_louvre_us'   \n",
      "1732786  weather_data_3.csv        0.0000  b'OpticalRainGauge'   \n",
      "1732787  weather_data_3.csv        0.0000  b'TippingRainGauge'   \n",
      "\n",
      "                            iotid                 timestamp       sensor_type  \\\n",
      "0        0a10aced202194944a0514dc 2024-10-19 11:56:31+00:00            b'voc'   \n",
      "1        0a10aced202194944a0514dc 2024-10-19 11:56:31+00:00       b'pressure'   \n",
      "2        0a10aced202194944a0514dc 2024-10-19 11:56:31+00:00       b'humidity'   \n",
      "3        0a10aced202194944a0514dc 2024-10-19 11:56:31+00:00       b'humidity'   \n",
      "4        0a10aced202194944a0514dc 2024-10-19 11:56:31+00:00    b'temperature'   \n",
      "...                           ...                       ...               ...   \n",
      "1732783  0a10aced202194944a050fdc 2024-10-19 11:53:47+00:00      b'windspeed'   \n",
      "1732784  0a10aced202194944a050fdc 2024-10-19 11:53:47+00:00  b'winddirection'   \n",
      "1732785  0a10aced202194944a050fdc 2024-10-19 11:53:47+00:00  b'winddirection'   \n",
      "1732786  0a10aced202194944a050fdc 2024-10-19 11:53:47+00:00       b'rainfall'   \n",
      "1732787  0a10aced202194944a050fdc 2024-10-19 11:53:47+00:00       b'rainfall'   \n",
      "\n",
      "         sample_time_length  \n",
      "0                      -1.0  \n",
      "1                      -1.0  \n",
      "2                      -1.0  \n",
      "3                      -1.0  \n",
      "4                      -1.0  \n",
      "...                     ...  \n",
      "1732783                -1.0  \n",
      "1732784                -1.0  \n",
      "1732785                -1.0  \n",
      "1732786               300.0  \n",
      "1732787               300.0  \n",
      "\n",
      "[1732788 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "flattened_weather_df = flatten_weather_data(combined_df)\n",
    "print(flattened_weather_df.columns)\n",
    "print(flattened_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e33771",
   "metadata": {},
   "source": [
    "Also need to add the sensor units to the dataframe and check the timestamp match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5a7cfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "sensor_units = {\n",
    "    'humidity': '%',\n",
    "    'pressure': 'hPa',\n",
    "    'rainfall': 'mm',\n",
    "    'temperature': 'C',\n",
    "    'voc': 'IAQ',\n",
    "    'winddirection': 'degrees',\n",
    "    'windspeed': 'm/s',\n",
    "}\n",
    "\n",
    "flattened_weather_df = add_sensor_units(flattened_weather_df,sensor_units)\n",
    "print(check_timestamp_match(flattened_weather_df))\n",
    "if len(check_timestamp_match(flattened_weather_df)) > 0:\n",
    "    print(\"Warning: Timestamps do not match\")\n",
    "    print(flattened_weather_df.loc[check_timestamp_match(flattened_weather_df)])\n",
    "else:\n",
    "    flattened_weather_df.drop(columns=['date_measured'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21dcde",
   "metadata": {},
   "source": [
    "Need to refactor the changes to the device information table into a separate function for adding a timezone and checking the timestamp. This can be seperate function since it is not dependent on the weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbaa309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['device_id', 'device_name', 'site_id', 'utc_offset_in_hours',\n",
      "       'longitude', 'latitude', 'timezone'],\n",
      "      dtype='object')\n",
      "device_id                           279\n",
      "device_name                     WH-0016\n",
      "site_id                              85\n",
      "utc_offset_in_hours                11.0\n",
      "longitude                    146.730825\n",
      "latitude                     -41.022719\n",
      "timezone               Australia/Hobart\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "devices_timezone_df = add_timezone_from_coordinates(devices_df)\n",
    "print(devices_timezone_df.columns)\n",
    "print(devices_timezone_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15c868",
   "metadata": {},
   "source": [
    "Alright now lets merge the weather and devices dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73c3cf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                                   7365694\n",
      "weather_reading_id                      9987227\n",
      "device_id                                   262\n",
      "source_file                  weather_data_1.csv\n",
      "device_name                             WH-0010\n",
      "site_id                                      57\n",
      "utc_offset_in_hours                        13.0\n",
      "longitude                            171.388011\n",
      "latitude                             -43.418845\n",
      "timestamp                  2024-10-19T15:22:02Z\n",
      "timezone                       Pacific/Auckland\n",
      "iotid                  0a10aced202194944a051624\n",
      "sensor_type                                 voc\n",
      "sensor_device                            BME680\n",
      "sensor_value                             12.044\n",
      "sensor_units                                IAQ\n",
      "sample_time_length                           -1\n",
      "Name: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(expanded_df.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e87faf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'weather_reading_id', 'device_id', 'source_file',\n",
      "       'sensor_value', 'sensor_device', 'iotid', 'timestamp', 'sensor_type',\n",
      "       'sample_time_length', 'sensor_units', 'device_name', 'site_id',\n",
      "       'utc_offset_in_hours', 'longitude', 'latitude', 'timezone'],\n",
      "      dtype='object')\n",
      "index                                    7243411\n",
      "weather_reading_id                       9983574\n",
      "device_id                                    259\n",
      "source_file                   weather_data_1.csv\n",
      "sensor_value                                 9.4\n",
      "sensor_device                          b'BME680'\n",
      "iotid                   0a10aced202194944a0514dc\n",
      "timestamp              2024-10-19 11:56:31+00:00\n",
      "sensor_type                               b'voc'\n",
      "sample_time_length                          -1.0\n",
      "sensor_units                                 nan\n",
      "device_name                              WH-0011\n",
      "site_id                                       63\n",
      "utc_offset_in_hours                         13.0\n",
      "longitude                             174.129735\n",
      "latitude                              -41.272475\n",
      "timezone                        Pacific/Auckland\n",
      "Name: 0, dtype: object\n",
      "index                                   7243411\n",
      "weather_reading_id                      9983574\n",
      "device_id                                   259\n",
      "source_file                  weather_data_1.csv\n",
      "device_name                             WH-0011\n",
      "site_id                                      63\n",
      "utc_offset_in_hours                        13.0\n",
      "longitude                            174.129735\n",
      "latitude                             -41.272475\n",
      "timestamp                  2024-10-19T11:56:31Z\n",
      "timezone                       Pacific/Auckland\n",
      "iotid                  0a10aced202194944a0514dc\n",
      "sensor_type                                 voc\n",
      "sensor_device                            BME680\n",
      "sensor_value                                9.4\n",
      "sensor_units                                IAQ\n",
      "sample_time_length                           -1\n",
      "Name: 0, dtype: object\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "\n",
      "Common columns: {'longitude', 'sensor_type', 'sensor_units', 'latitude', 'iotid', 'device_id', 'timestamp', 'timezone', 'sensor_device', 'source_file', 'sensor_value', 'sample_time_length', 'site_id', 'device_name', 'weather_reading_id', 'index', 'utc_offset_in_hours'}\n",
      "Match: False\n"
     ]
    }
   ],
   "source": [
    "final_df = merge_weather_data(flattened_weather_df,devices_timezone_df)\n",
    "print(final_df.columns)\n",
    "final_row = final_df.loc[0]\n",
    "print(final_row)\n",
    "#compare to original combined_merged_df\n",
    "flattened_row  = flattened_df.loc[0]  \n",
    "print(flattened_row)\n",
    "# find the difference in columns\n",
    "print(final_df.columns.difference(flattened_df.columns))\n",
    "print(flattened_df.columns.difference(final_df.columns))\n",
    "# Find columns that are in both dataframes but have different names\n",
    "common_values = set(final_df.columns) & set(flattened_df.columns)\n",
    "print(\"\\nCommon columns:\", common_values)\n",
    "print(\"Match:\", (final_row[list(common_values)] == flattened_row[list(common_values)]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4d438",
   "metadata": {},
   "source": [
    "Great that works and is much faster. Need to now add the functionality to the package for the end user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "671fd3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading JSON file: File not found: /home/zach/repo/data.data_engineer_technical_challenge/notebooks/src/bioscout_tech_challenge/sensor_schema.json\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Lets try and load the sensor schema from a json file.\n",
    "sensor_schema = read_json_file(r\"src/bioscout_tech_challenge/sensor_schema.json\")\n",
    "print(parse_sensor_schema(sensor_schema))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73b5a2",
   "metadata": {},
   "source": [
    "# CLI Development\n",
    "\n",
    "Lets see what the cli can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b9566ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: bioscout-tech-challenge weather [-h] {flatten,merge,filter} ...\n",
      "\n",
      "positional arguments:\n",
      "  {flatten,merge,filter}\n",
      "    flatten             Flatten weather data from a CSV file or directory of\n",
      "                        CSV files. Extracts additional sensor data from the\n",
      "                        extra_information column and merges it with the\n",
      "                        weather data.\n",
      "    merge               Merge weather data with device information from a CSV\n",
      "                        file. Can merge either a single weather CSV file or an\n",
      "                        entire directory of weather files.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "! (bioscout-tech-challenge weather --help)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20422796",
   "metadata": {},
   "source": [
    "CLI is working as expected lets merge and save the data through the cli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f256f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m2024-12-12 10:57:55,415\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mpyapp.app\u001b[39m Starting bioscout-tech-challenge version Unknown - Bioscout Tech Challenge CLI\n",
      "\u001b[33m2024-12-12 10:57:55,424\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mpyapp.conf\u001b[39m Loading settings from: python:bioscout_tech_challenge.default_settings\n",
      "\u001b[33m2024-12-12 10:57:55,429\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mbioscout_tech_challenge.cli\u001b[39m Flattening directory ../data/tables/weather_data\n",
      "\u001b[33m2024-12-12 10:57:55,459\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mbioscout_tech_challenge.cli\u001b[39m Reading sensor schema from /home/zach/repo/data.data_engineer_technical_challenge/src/bioscout_tech_challenge/sensor_schema.json\n",
      "\u001b[33m2024-12-12 10:58:50,556\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mbioscout_tech_challenge.cli\u001b[39m Flattened 3 files and saved to /home/zach/repo/data.data_engineer_technical_challenge/data/tables/weather_data/flattened/weather_data_flattened.csv\n"
     ]
    }
   ],
   "source": [
    "! (bioscout-tech-challenge weather flatten --combine --directory=../data/tables/weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3965fff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m2024-12-12 10:50:45,633\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mpyapp.app\u001b[39m Starting bioscout-tech-challenge version Unknown - Bioscout Tech Challenge CLI\n",
      "\u001b[33m2024-12-12 10:50:45,640\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mpyapp.conf\u001b[39m Loading settings from: python:bioscout_tech_challenge.default_settings\n",
      "\u001b[33m2024-12-12 10:50:45,646\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mbioscout_tech_challenge.cli\u001b[39m Read device data from ../data/tables/weather_data/weather_devices.csv\n",
      "\u001b[33m2024-12-12 10:50:51,198\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mbioscout_tech_challenge.cli\u001b[39m Using single file: ../data/tables/weather_data/flattened/weather_data_flattened.csv\n",
      "../data/tables/weather_data/output/exploration_data_output.csv\n",
      "\u001b[33m2024-12-12 10:50:55,238\u001b[39m \u001b[90mDEBUG\u001b[0m \u001b[94mbioscout_tech_challenge.cli\u001b[39m Read weather data from ../data/tables/weather_data/flattened/weather_data_flattened.csv\n",
      "\u001b[33m2024-12-12 10:50:56,490\u001b[39m \u001b[90mDEBUG\u001b[0m \u001b[94mbioscout_tech_challenge.cli\u001b[39m Merged data for ../data/tables/weather_data/flattened/weather_data_flattened.csv\n",
      "\u001b[33m2024-12-12 10:51:07,193\u001b[39m \u001b[32mINFO\u001b[0m \u001b[94mbioscout_tech_challenge.cli\u001b[39m Saved merged data to ../data/tables/weather_data/output/exploration_data_output.csv\n"
     ]
    }
   ],
   "source": [
    "! (bioscout-tech-challenge weather merge -tz \\\n",
    "--file=../data/tables/weather_data/flattened/weather_data_flattened.csv \\\n",
    "--device_csv=../data/tables/weather_data/weather_devices.csv \\\n",
    "--output=../data/tables/weather_data/output/exploration_data_output.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98242a",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations\n",
    "We have found a way to efficently extact the sensor data from the extra_inforamtion column and add it to the main dataframe. We have also found a way to merge the weather and devices dataframes and add a timezone column.\n",
    "This has been integrated into the cli tool and can be used to pre-process the weather data for the visualisation and analysis tasks. If there is additional sensors added we can easily update the sensor schema and re-run the cli commands. Additionally information such as meta data and columns to drop can be easily modified through this schema. The schema is stored in the `src/bioscout_tech_challenge/sensor_schema.json` file and is shown below.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"sensor_types\": [\n",
    "        \"VOCs\",\n",
    "        \"Pressure\",\n",
    "        \"Humidity\",\n",
    "        \"Temperature\",\n",
    "        \"WindSpeed\",\n",
    "        \"WindDirection\",\n",
    "        \"Rainfall\"\n",
    "    ],\n",
    "    \"sensor_units\": {\n",
    "        \"voc\": \"IAQ\",\n",
    "        \"humidity\": \"%\",\n",
    "        \"pressure\": \"hPa\",\n",
    "        \"rainfall\": \"mm\",\n",
    "        \"temperature\": \"C\",\n",
    "        \"windspeed\": \"m/s\",\n",
    "        \"winddirection\": \"degrees\"\n",
    "    },\n",
    "    \"meta_columns\": [\n",
    "        \"IotID\",\n",
    "        \"Timestamp\"\n",
    "    ],\n",
    "    \"column_mapping\": {\n",
    "        \"Value\": \"sensor_value\",\n",
    "        \"Sensor\": \"sensor_device\",\n",
    "        \"IotID\": \"iotid\",\n",
    "        \"SampleTimeLength\": \"sample_time_length\",\n",
    "        \"Timestamp\": \"timestamp\"\n",
    "    },\n",
    "    \"columns_to_drop\": [\n",
    "        \"extra_information\",\n",
    "        \"pressure\",\n",
    "        \"voc\",\n",
    "        \"date_measured\"\n",
    "    ],\n",
    "    \"column_types\": {\n",
    "        \"sensor_value\": \"float\",\n",
    "        \"sample_time_length\": \"int\"\n",
    "    }\n",
    "} \n",
    "```\n",
    "\n",
    "### Future Work\n",
    " - This can only be considered a proof of concept and is not ready for production. We need to add more robust error handling and testing as well as consultation with the end user to determine how the data will be used and what additional functionality is required.\n",
    " - We will also need to consult with the engineering team to determine the best way to store the data in the database as it is not currently in a format that is easily accessible for the end user.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
